{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5650ae8b6dd44098ac8e2e5aca4cfe5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d76de50b0f943c1a7c5c0f6a2849e7d",
              "IPY_MODEL_3b247e36e6e54ddd9d1e4b895302c2fa",
              "IPY_MODEL_f6adaaa421764cafad76dbe47ca8a733"
            ],
            "layout": "IPY_MODEL_0193651cabc14fca87bc60e3787a821b"
          }
        },
        "2d76de50b0f943c1a7c5c0f6a2849e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_536d05b74b874ad79dce63086f33229d",
            "placeholder": "​",
            "style": "IPY_MODEL_efc14e445c964af5a095af5c3f943fc3",
            "value": "Loading weights: 100%"
          }
        },
        "3b247e36e6e54ddd9d1e4b895302c2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77dbb07ee5bd4def93a0215c53f0b4ec",
            "max": 195,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfc8d50655754f61abe0eb9bd554c44c",
            "value": 195
          }
        },
        "f6adaaa421764cafad76dbe47ca8a733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72b1fb24f6c348df9ca3f3a0285fc92a",
            "placeholder": "​",
            "style": "IPY_MODEL_b85531a46a814156a7596ef0961eb1ff",
            "value": " 195/195 [00:25&lt;00:00,  4.65it/s, Materializing param=model.norm.weight]"
          }
        },
        "0193651cabc14fca87bc60e3787a821b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536d05b74b874ad79dce63086f33229d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efc14e445c964af5a095af5c3f943fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77dbb07ee5bd4def93a0215c53f0b4ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfc8d50655754f61abe0eb9bd554c44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72b1fb24f6c348df9ca3f3a0285fc92a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85531a46a814156a7596ef0961eb1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation des dépendances et Imports\n",
        "Librairies nécessaires (Transformers, Faker, Accelerate)."
      ],
      "metadata": {
        "id": "Xx5ySYd-X4oV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyXvLHw7SX_L",
        "outputId": "019f70ab-9fb2-4dee-e0fb-fa5d0a28d6d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            " Environnement prêt. Exécution sur : cuda\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q git+https://github.com/huggingface/transformers\n",
        "!pip install -q accelerate bitsandbytes faker\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from faker import Faker\n",
        "import re\n",
        "import hashlib\n",
        "import random\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Configuration du device (GPU recommandé)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\" Environnement prêt. Exécution sur : {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Génération de Données : Documents Synthétiques (Faker)\n",
        " Nous utilisons Faker pour générer une note fiscale factice contenant des PII (Informations Identifiables Personnellement).\n"
      ],
      "metadata": {
        "id": "FaIU18OPXufB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake = Faker('fr_FR')\n",
        "\n",
        "def generate_fake_tax_document():\n",
        "    \"\"\"Génère un document fiscal factice avec des entités nommées.\"\"\"\n",
        "\n",
        "    # Génération d'entités\n",
        "    nom_personne = fake.name()\n",
        "    entreprise = fake.company()\n",
        "    siret = fake.siret().replace(\" \", \"\")\n",
        "    adresse = fake.address().replace(\"\\n\", \", \")\n",
        "    iban = fake.iban()\n",
        "    age = random.randint(25, 65)\n",
        "    revenu = random.randint(30000, 80000)\n",
        "    impot = int(revenu * 0.15)\n",
        "    date_doc = fake.date_this_year().strftime(\"%d/%m/%Y\")\n",
        "\n",
        "    # Modèle de texte (Note fiscale)\n",
        "    document = f\"\"\"\n",
        "    RÉPUBLIQUE FRANÇAISE - AVIS D'IMPÔT {datetime.now().year}\n",
        "\n",
        "    DESTINATAIRE :\n",
        "    Monsieur/Madame {nom_personne}\n",
        "    Né(e) le : {fake.date_of_birth(minimum_age=age, maximum_age=age)} ({age} ans)\n",
        "    Adresse : {adresse}\n",
        "\n",
        "    RÉFÉRENCES :\n",
        "    SIRET de l'employeur principal : {siret} ({entreprise})\n",
        "    Numéro Fiscal : {random.randint(1000000000000, 9999999999999)}\n",
        "\n",
        "    DÉTAILS FINANCIERS :\n",
        "    Revenu Brut Global : {revenu} €\n",
        "    Montant de l'impôt à payer : {impot} €\n",
        "\n",
        "    PAIEMENT :\n",
        "    Prélèvement automatique sur le compte {iban}\n",
        "    Date limite : {date_doc}\n",
        "    \"\"\"\n",
        "    return document, {\"nom\": nom_personne, \"org\": entreprise, \"age\": age, \"revenu\": revenu, \"iban\": iban}\n",
        "\n",
        "# Générer et afficher un exemple\n",
        "doc_original, entites_verite = generate_fake_tax_document()\n",
        "print(\"--- DOCUMENT ORIGINAL GÉNÉRÉ ---\")\n",
        "print(doc_original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYxrzDfrXmRt",
        "outputId": "c5c8fa31-93f5-4539-eafb-46ec368dc8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DOCUMENT ORIGINAL GÉNÉRÉ ---\n",
            "\n",
            "    RÉPUBLIQUE FRANÇAISE - AVIS D'IMPÔT 2026\n",
            "\n",
            "    DESTINATAIRE :\n",
            "    Monsieur/Madame Olivier Louis\n",
            "    Né(e) le : 1984-08-24 (41 ans)\n",
            "    Adresse : 69, avenue Jean Guillou, 72159 Saint Juliette\n",
            "\n",
            "    RÉFÉRENCES :\n",
            "    SIRET de l'employeur principal : 33543975800095 (Delattre Martineau SARL)\n",
            "    Numéro Fiscal : 6942570143058\n",
            "\n",
            "    DÉTAILS FINANCIERS :\n",
            "    Revenu Brut Global : 54669 €\n",
            "    Montant de l'impôt à payer : 8200 €\n",
            "\n",
            "    PAIEMENT :\n",
            "    Prélèvement automatique sur le compte FR1910436626999571265498872\n",
            "    Date limite : 02/01/2026\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "2oWS_qoda5V3",
        "outputId": "add8930c-b329-4e6f-e455-411f5f45b72d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (5.0.0.dev0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.49.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (1.2.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers) (0.20.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.9.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers) (1.5.4)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.2.1->transformers) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->transformers) (8.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.2.1->transformers) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chargement du Modèle Phi-3 Mini"
      ],
      "metadata": {
        "id": "i4ktqXOiYfBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "model_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "print(\" Chargement du tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "print(\" Chargement du modèle (Version Native)...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=False,\n",
        "    attn_implementation=\"eager\"\n",
        ")\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "print(\" Modèle Phi-3 Mini chargé avec succès !\")\n",
        "\n",
        "# Test rapide pour vérifier que ça marche\n",
        "test_input = [{\"role\": \"user\", \"content\": \"Bonjour, écris une phrase de test.\"}]\n",
        "print(pipe(test_input, max_new_tokens=20)[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290,
          "referenced_widgets": [
            "5650ae8b6dd44098ac8e2e5aca4cfe5c",
            "2d76de50b0f943c1a7c5c0f6a2849e7d",
            "3b247e36e6e54ddd9d1e4b895302c2fa",
            "f6adaaa421764cafad76dbe47ca8a733",
            "0193651cabc14fca87bc60e3787a821b",
            "536d05b74b874ad79dce63086f33229d",
            "efc14e445c964af5a095af5c3f943fc3",
            "77dbb07ee5bd4def93a0215c53f0b4ec",
            "dfc8d50655754f61abe0eb9bd554c44c",
            "72b1fb24f6c348df9ca3f3a0285fc92a",
            "b85531a46a814156a7596ef0961eb1ff"
          ]
        },
        "id": "45P7WNiJYcFI",
        "outputId": "b050f9c4-5bc0-4751-cc3f-80e9ca560147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Chargement du tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Chargement du modèle (Version Native)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/195 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5650ae8b6dd44098ac8e2e5aca4cfe5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Modèle Phi-3 Mini chargé avec succès !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=20) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'user', 'content': 'Bonjour, écris une phrase de test.'}, {'role': 'assistant', 'content': ' \"Bonjour, je voudrais tester la fonctionnalité de prise en'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions & Inférence (Le Cœur de l'Anonymisation)\n",
        "Nous définissons le **System Prompt** pour instruire le modèle sur les règles de remplacement.\n"
      ],
      "metadata": {
        "id": "zNIEB3AnYqfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définition des règles pour le modèle\n",
        "system_prompt = \"\"\"Vous êtes un assistant expert en protection des données et anonymisation (RGPD).\n",
        "Votre tâche est de réécrire le document fiscal fourni en appliquant STRICTEMENT les règles suivantes :\n",
        "\n",
        "1. Noms de personnes : Remplacer par [PERSONNE_1], [PERSONNE_2]...\n",
        "2. Entreprises : Remplacer par [ENTREPRISE_1]...\n",
        "3. Adresses postales complètes : Remplacer par [ADRESSE_SUPPRIMEE]\n",
        "4. Identifiants (IBAN, SIRET, Numéro Fiscal) : Remplacer par [SUPPRIME]\n",
        "5. Âges : Généraliser par une tranche de 10 ans (ex: 35 ans -> [30-40 ans]).\n",
        "6. Montants financiers : Remplacer par une tranche (Banding) (ex: 47 523€ -> [40k-50k€]).\n",
        "\n",
        "Ne changez pas la structure du document. Ne conservez AUCUNE donnée sensible réelle.\n",
        "\"\"\"\n",
        "\n",
        "# Construction de la conversation\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": f\"Voici le document à anonymiser :\\n\\n{doc_original}\"}\n",
        "]\n",
        "\n",
        "# Paramètres de génération\n",
        "generation_args = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"return_full_text\": False,\n",
        "    \"temperature\": 0.1, # Température basse pour être déterministe et suivre les règles\n",
        "    \"do_sample\": True,\n",
        "}\n",
        "\n",
        "# Inférence\n",
        "print(\" Anonymisation en cours avec Phi-3...\")\n",
        "output = pipe(messages, **generation_args)\n",
        "doc_anonymise_llm = output[0]['generated_text']\n",
        "\n",
        "print(\"\\n--- RÉSULTAT DU MODÈLE (Inférence) ---\")\n",
        "print(doc_anonymise_llm)"
      ],
      "metadata": {
        "id": "mRSb4Q3MYmmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185fee29-fe7f-4f38-a532-730bde301ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=500) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Anonymisation en cours avec Phi-3...\n",
            "\n",
            "--- RÉSULTAT DU MODÈLE (Inférence) ---\n",
            " Voici le document anonymisé :\n",
            "\n",
            "\n",
            "    RÉPUBLIQUE FRANÇAISE - AVIS D'IMPÔT 2026\n",
            "\n",
            "    DESTINATAIRE :\n",
            "    [PERSONNE_1]\n",
            "    Né(e) le : [30-40 ans] (41 ans)\n",
            "    Adresse : [ADRESSE_SUPPRIMEE]\n",
            "\n",
            "    RÉFÉRENCES :\n",
            "    SIRET de l'employeur principal : [SUPPRIME]\n",
            "    Numéro Fiscal : [SUPPRIME]\n",
            "\n",
            "    DÉTAILS FINANCIERS :\n",
            "    Revenu Brut Global : [40k-50k€]\n",
            "    Montant de l'impôt à payer : [40k-50k€]\n",
            "\n",
            "    PAIEMENT :\n",
            "    Prélèvement automatique sur le compte [SUPPRIME]\n",
            "    Date limite : 02/01/2026\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Fonctions Python Complémentaires (HMAC & Banding Avancé)\n",
        "\n",
        " Pour les calculs mathématiques  (Hashing SHA256, Banding exact), il est préférable d'utiliser le LLM pour *taguer* les entités, puis Python pour calculer.\n"
      ],
      "metadata": {
        "id": "Basa0kT6ZCia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def hmac_sha256_anonymizer(valeur, secret_key=\"mon_secret_fiscal\"):\n",
        "    \"\"\"Hache une valeur (âge, id) avec une clé secrète.\"\"\"\n",
        "    message = str(valeur).encode()\n",
        "    key = secret_key.encode()\n",
        "    return hashlib.sha256(key + message).hexdigest()[:10] # On garde les 10 premiers caractères\n",
        "\n",
        "def financial_banding(montant):\n",
        "    \"\"\"Transforme un montant exact en tranche.\"\"\"\n",
        "    # Arrondi au 10k le plus proche pour l'exemple\n",
        "    lower = (montant // 10000) * 10000\n",
        "    upper = lower + 10000\n",
        "    return f\"[{lower/1000}k-{upper/1000}k€]\"\n",
        "\n",
        "print(\"--- DÉMONSTRATION PYTHON (Règles strictes) ---\")\n",
        "print(f\"Âge original ({entites_verite['age']}) -> Hash HMAC : {hmac_sha256_anonymizer(entites_verite['age'])}\")\n",
        "print(f\"Revenu original ({entites_verite['revenu']}€) -> Banding : {financial_banding(entites_verite['revenu'])}\")"
      ],
      "metadata": {
        "id": "Q4GXFxsgZAKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea0cc19-0f91-40b7-bdb3-165e01511ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DÉMONSTRATION PYTHON (Règles strictes) ---\n",
            "Âge original (41) -> Hash HMAC : 9049a53264\n",
            "Revenu original (54669€) -> Banding : [50.0k-60.0k€]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Validation (Contrôle Regex)\n",
        " Un script de sécurité vérifie qu'aucun format sensible n'a \"fuité\" dans la sortie du modèle.\n"
      ],
      "metadata": {
        "id": "dqd4PHMRZcL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_securite(texte):\n",
        "    alertes = []\n",
        "\n",
        "    # Regex Patterns pour la France\n",
        "    patterns = {\n",
        "        \"IBAN_FR\": r\"FR\\d{2}[ ]?\\d{4}[ ]?\\d{4}[ ]?\\d{4}[ ]?\\d{4}[ ]?\\d{2}\",\n",
        "        \"SIRET\": r\"\\d{14}\",\n",
        "        \"MONTANT_EXACT\": r\"\\d{2,3}\\s?\\d{3}\\s?€\", # Détecte des montants comme 45 000 € non floutés\n",
        "        \"EMAIL\": r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"\n",
        "    }\n",
        "\n",
        "    score_securite = 100\n",
        "\n",
        "    for type_donnee, pattern in patterns.items():\n",
        "        matches = re.findall(pattern, texte)\n",
        "        if matches:\n",
        "            alertes.append(f\" ALERTE : {len(matches)} {type_donnee} détecté(s) ! (ex: {matches[0]})\")\n",
        "            score_securite -= 25\n",
        "\n",
        "    if not alertes:\n",
        "        return \" Validation RÉUSSIE. Aucune donnée sensible détectée par Regex.\", 100\n",
        "    else:\n",
        "        return \"\\n\".join(alertes), score_securite\n",
        "\n",
        "# Lancer la validation sur le texte produit par Phi-3\n",
        "rapport, score = validation_securite(doc_anonymise_llm)\n",
        "\n",
        "print(\"--- RAPPORT DE VALIDATION ---\")\n",
        "print(rapport)\n",
        "print(f\"Score de conformité : {score}/100\")"
      ],
      "metadata": {
        "id": "fsNsdnOHZZWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "260e204b-b993-4fcb-9e51-cfb85ca92784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- RAPPORT DE VALIDATION ---\n",
            " Validation RÉUSSIE. Aucune donnée sensible détectée par Regex.\n",
            "Score de conformité : 100/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculer_score_confidentialite(texte_original, entites_reelles, texte_anonymise):\n",
        "    \"\"\"\n",
        "    Calcule si les valeurs réelles (Faker) sont encore présentes dans le texte anonymisé.\n",
        "    TP (Vrai Positif) = Donnée sensible correctement supprimée.\n",
        "    FN (Faux Négatif) = Donnée sensible encore présente (Fuite/Leak).\n",
        "    \"\"\"\n",
        "    stats = {\n",
        "        \"total_secrets\": 0,\n",
        "        \"secrets_supprimes\": 0,\n",
        "        \"fuites\": []\n",
        "    }\n",
        "\n",
        "    # Liste des valeurs à vérifier (Nom, IBAN, SIRET, etc.)\n",
        "    valeurs_a_cacher = [\n",
        "        str(entites_reelles['nom']),\n",
        "        str(entites_reelles['iban']),\n",
        "        str(entites_reelles['org']),\n",
        "        str(entites_reelles['revenu']), # Le montant exact doit disparaître\n",
        "        str(entites_reelles['siret']) if 'siret' in entites_reelles else None\n",
        "    ]\n",
        "\n",
        "    # Nettoyage des valeurs None\n",
        "    valeurs_a_cacher = [v for v in valeurs_a_cacher if v]\n",
        "\n",
        "    stats[\"total_secrets\"] = len(valeurs_a_cacher)\n",
        "\n",
        "    print(\"--- DÉTAIL DU SCAN ---\")\n",
        "    for secret in valeurs_a_cacher:\n",
        "        # On vérifie si le secret est dans le texte (insensible à la casse)\n",
        "        if secret.lower() in texte_anonymise.lower():\n",
        "            print(f\" FUITE DÉTECTÉE : '{secret}' est encore visible !\")\n",
        "            stats[\"fuites\"].append(secret)\n",
        "        else:\n",
        "            print(f\" PROTEGÉ : '{secret}' a bien disparu.\")\n",
        "            stats[\"secrets_supprimes\"] += 1\n",
        "\n",
        "    # Calcul du Recall (Rappel)\n",
        "    recall = (stats[\"secrets_supprimes\"] / stats[\"total_secrets\"]) * 100 if stats[\"total_secrets\"] > 0 else 0\n",
        "\n",
        "    return recall, stats\n",
        "\n",
        "\n",
        "if 'entites_verite' in globals() and 'doc_anonymise_llm' in globals():\n",
        "    score, details = calculer_score_confidentialite(doc_original, entites_verite, doc_anonymise_llm)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*30)\n",
        "    print(f\" SCORE DE CONFIDENTIALITÉ (Recall) : {score:.2f}%\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    if score == 100:\n",
        "        print(\"Excellent ! Toutes les données identifiées ont été masquées/transformées.\")\n",
        "    else:\n",
        "        print(f\"Attention, il reste {len(details['fuites'])} données sensibles.\")\n",
        "else:\n",
        "    print(\"Erreur : Veuillez d'abord lancer la génération Faker et l'inférence Phi-3 (étapes 2 et 4).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2K1PUs-SpwHn",
        "outputId": "14a88c50-19c2-4082-a940-9bff3076bf44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- DÉTAIL DU SCAN ---\n",
            " PROTEGÉ : 'Olivier Louis' a bien disparu.\n",
            " PROTEGÉ : 'FR1910436626999571265498872' a bien disparu.\n",
            " PROTEGÉ : 'Delattre Martineau SARL' a bien disparu.\n",
            " PROTEGÉ : '54669' a bien disparu.\n",
            "\n",
            "==============================\n",
            " SCORE DE CONFIDENTIALITÉ (Recall) : 100.00%\n",
            "==============================\n",
            "Excellent ! Toutes les données identifiées ont été masquées/transformées.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Cela va monter votre Drive dans le dossier /content/drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "print(\" Google Drive connecté !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPHRhqStouTF",
        "outputId": "fa42f89c-0bb6-4014-8dbd-0e127c5efd8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " Google Drive connecté !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 4. Anonymisation (Code Robuste & Sécurisé)\n",
        "import torch\n",
        "\n",
        "# 1. Préparation propre des inputs\n",
        "# On s'assure que le modèle et les inputs sont sur le même device (GPU)\n",
        "device = model.device\n",
        "\n",
        "# Création du prompt\n",
        "messages_perso = [\n",
        "    {\"role\": \"system\", \"content\": system_prompt},\n",
        "    {\"role\": \"user\", \"content\": f\"Voici le document à anonymiser :\\n\\n{texte_extrait}\"}\n",
        "]\n",
        "\n",
        "# 2. Tokenization sécurisée\n",
        "# On génère les ID de tokens\n",
        "input_ids = tokenizer.apply_chat_template(\n",
        "    messages_perso,\n",
        "    return_tensors=\"pt\",\n",
        "    add_generation_prompt=True\n",
        ").to(device)\n",
        "\n",
        "# 3. Vérification de la longueur (Sécurité context window)\n",
        "# Phi-3-mini supporte 4096 tokens. Si on dépasse, ça plante.\n",
        "longueur_input = input_ids.shape[1]\n",
        "print(f\" Longueur de l'entrée : {longueur_input} tokens (Max: 4096)\")\n",
        "\n",
        "if longueur_input > 3500:\n",
        "    print(\" ATTENTION : Document très long. Je ne garde qu'une partie.\")\n",
        "    # On garde le system prompt (début) et la fin du document\n",
        "    pass\n",
        "\n",
        "# 4. Lancement de l'Inférence\n",
        "print(\"\\n Démarrage de l'IA...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# On redéfinit le streamer au cas où\n",
        "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
        "\n",
        "# CORRECTION MAJEURE ICI : On passe explicitement 'input_ids' par mot-clé\n",
        "try:\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        streamer=streamer,\n",
        "        max_new_tokens=1500,\n",
        "        temperature=0.1,\n",
        "        do_sample=True,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Erreur pendant la génération : {e}\")\n",
        "    print(\"Conseil : Essayez de réduire la taille du document ou de redémarrer le runtime.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "wZpVCC17pFdj",
        "outputId": "ac142671-259b-4b22-d8a3-2b503539e95e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'shape'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2654423780.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# 3. Vérification de la longueur (Sécurité context window)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Phi-3-mini supporte 4096 tokens. Si on dépasse, ça plante.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mlongueur_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\" Longueur de l'entrée : {longueur_input} tokens (Max: 4096)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: "
          ]
        }
      ]
    }
  ]
}